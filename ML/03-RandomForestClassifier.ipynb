{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___\n",
    "___\n",
    "# RandomForestClassifier\n",
    "___\n",
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/utilisateur/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['City', 'State', 'Zip', 'Bank', 'BankState', 'NAICS', 'ApprovalDate',\n",
       "       'ApprovalFY', 'Term', 'NoEmp', 'NewExist', 'CreateJob', 'RetainedJob',\n",
       "       'FranchiseCode', 'UrbanRural', 'RevLineCr', 'LowDoc', 'MIS_Status',\n",
       "       'GrAppv', 'SBA_Appv', 'NAICS2', 'DiffJobs'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "\n",
    "df = pd.read_csv('./data_set/SBAnational-EDA.csv')\n",
    "df = df.drop(columns=['Unnamed: 0'], axis=1).reset_index(drop=True)\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = df.groupby(['ApprovalFY', 'MIS_Status']).size().reset_index(name='count')\n",
    "\n",
    "# Pivoter les résultats\n",
    "dd = dd.pivot(index='ApprovalFY', columns='MIS_Status', values='count').reset_index()\n",
    "\n",
    "# Remplacer les NaN par 0\n",
    "dd.fillna(0, inplace=True)\n",
    "\n",
    "# Créer une nouvelle colonne basée sur la comparaison 'CHGOFF' > 'P I F'\n",
    "dd['ApprovalFY_bool'] = dd.apply(lambda row: 0 if row['CHGOFF'] > row['P I F'] else 1, axis=1)\n",
    "\n",
    "dd = dd[['ApprovalFY_bool']]\n",
    "\n",
    "df = pd.concat([df, dd], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\n",
    "    'City',\n",
    "    'State',\n",
    "    'Zip',\n",
    "    'Bank',\n",
    "    'BankState',\n",
    "    'NAICS',\n",
    "    # 'NAICS2',\n",
    "    'ApprovalDate',\n",
    "    'ApprovalFY',\n",
    "    # 'ApprovalFY_bool',\n",
    "    'Term',\n",
    "    'NoEmp',\n",
    "    'NewExist',\n",
    "    'CreateJob',\n",
    "    'RetainedJob',\n",
    "    'DiffJobs',\n",
    "    'FranchiseCode',\n",
    "    'UrbanRural',\n",
    "    'RevLineCr',\n",
    "    'LowDoc',\n",
    "    'GrAppv',\n",
    "    'SBA_Appv',\n",
    "    'MIS_Status',\n",
    "    ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>City</th>\n",
       "      <td>EVANSVILLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zip</th>\n",
       "      <td>47711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bank</th>\n",
       "      <td>FIFTH THIRD BANK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BankState</th>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NAICS</th>\n",
       "      <td>451120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ApprovalDate</th>\n",
       "      <td>1997-02-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ApprovalFY</th>\n",
       "      <td>1997-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term</th>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NoEmp</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NewExist</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CreateJob</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RetainedJob</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiffJobs</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FranchiseCode</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UrbanRural</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RevLineCr</th>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LowDoc</th>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GrAppv</th>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SBA_Appv</th>\n",
       "      <td>48000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MIS_Status</th>\n",
       "      <td>P I F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              0\n",
       "City                 EVANSVILLE\n",
       "State                        IN\n",
       "Zip                       47711\n",
       "Bank           FIFTH THIRD BANK\n",
       "BankState                    IN\n",
       "NAICS                    451120\n",
       "ApprovalDate         1997-02-28\n",
       "ApprovalFY           1997-01-01\n",
       "Term                         84\n",
       "NoEmp                         4\n",
       "NewExist                    2.0\n",
       "CreateJob                     0\n",
       "RetainedJob                   0\n",
       "DiffJobs                      0\n",
       "FranchiseCode                 0\n",
       "UrbanRural                    0\n",
       "RevLineCr                     N\n",
       "LowDoc                        Y\n",
       "GrAppv                  60000.0\n",
       "SBA_Appv                48000.0\n",
       "MIS_Status                P I F"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Zip', 'NAICS', 'Term', 'NoEmp', 'NewExist', 'CreateJob', 'RetainedJob', 'DiffJobs', 'FranchiseCode', 'UrbanRural', 'GrAppv', 'SBA_Appv']\n",
      "['City', 'State', 'Bank', 'BankState', 'ApprovalDate', 'ApprovalFY', 'RevLineCr', 'LowDoc', 'MIS_Status']\n"
     ]
    }
   ],
   "source": [
    "colonnes_numeriques = df.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "# Sélectionner les colonnes non numériques\n",
    "colonnes_non_numeriques = df.drop(columns=colonnes_numeriques).columns.tolist()\n",
    "\n",
    "print(colonnes_numeriques)\n",
    "print(colonnes_non_numeriques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes avec des valeurs manquantes :\n",
      " State         6\n",
      "Bank         25\n",
      "BankState    25\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Créer un nouveau DataFrame sans les lignes contenant des valeurs NaN\n",
    "# df = df.dropna()\n",
    "\n",
    "# Vérifier s'il y a des valeurs manquantes dans le DataFrame\n",
    "missing_values = df.isnull().sum()\n",
    "# Afficher les colonnes avec des valeurs manquantes\n",
    "print(\"Colonnes avec des valeurs manquantes :\\n\", missing_values[missing_values > 0])\n",
    "\n",
    "# Vérifier les types de données de chaque colonne\n",
    "# data_types = df.dtypes\n",
    "# Afficher les types de données de chaque colonne\n",
    "# print(\"Types de données de chaque colonne :\\n\", data_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "grid_search_bool = False\n",
    "\n",
    "numerical_features = make_column_selector(dtype_include=np.number)\n",
    "categorical_features = make_column_selector(dtype_exclude=np.number)\n",
    "\n",
    "# Définir le preprocessor\n",
    "label_encoder = LabelEncoder()\n",
    "preprocessor = make_column_transformer(\n",
    "    (make_pipeline(SimpleImputer(), StandardScaler()), numerical_features),\n",
    "    (make_pipeline(SimpleImputer(strategy='most_frequent'), OneHotEncoder(drop='if_binary')), categorical_features),\n",
    ")\n",
    "\n",
    "# Prétraiter les données\n",
    "X = preprocessor.fit_transform(df.drop(columns='MIS_Status'))\n",
    "y = label_encoder.fit_transform(df['MIS_Status'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, test_size=0.05, random_state=42, stratify=y)\n",
    "# y_train = y_train.astype(int).tolist()\n",
    "# y_test = y_test.astype(int).tolist()\n",
    "\n",
    "if grid_search_bool == False:\n",
    "    # LGBM\n",
    "    d_train = lgb.Dataset(X_train, label=y_train)\n",
    "\n",
    "    # https://lightgbm.readthedocs.io/en/latest/Parameters.html\n",
    "    # best f1 macro : 0.9154\n",
    "    # \n",
    "\n",
    "    # RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "    #                    criterion='gini', max_depth=None, max_features='sqrt',\n",
    "    #                    max_leaf_nodes=None, max_samples=None,\n",
    "    #                    min_impurity_decrease=0.0, min_samples_leaf=1,\n",
    "    #                    min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "    #                    n_estimators=100, n_jobs=-1, oob_score=False,\n",
    "    #                    random_state=0, verbose=0, warm_start=False)\n",
    "\n",
    "\n",
    "    start=datetime.now()\n",
    "    rf_classifier = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                criterion='gini', max_depth=None, max_features='sqrt',\n",
    "                max_leaf_nodes=None, max_samples=None,\n",
    "                min_impurity_decrease=0.0, min_samples_leaf=1,\n",
    "                min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "                n_estimators=100, n_jobs=-1, oob_score=False,\n",
    "                random_state=0, verbose=0, warm_start=False)\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "    stop=datetime.now()\n",
    "    execution_time_rfc = stop-start\n",
    "\n",
    "    #Prediction on test data\n",
    "    # y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "    #convert into binary values 0/1 for classification\n",
    "    # y_pred_lgbm = [list(x).index(max(x)) for x in y_pred_lgbm]\n",
    "\n",
    "    print(execution_time_rfc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### PICKEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = './model/modelRFC.pkl'\n",
    "\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(rf_classifier, file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
